import sys
import requests
import html
import pandas as pd
from bs4 import BeautifulSoup

# ä¿®æ­£ Windows cmd ç·¨ç¢¼å•é¡Œ
sys.stdout.reconfigure(encoding="utf-8")

# ç›®æ¨™ URLï¼ˆæ›æˆä½ çš„å…¬è»Šè·¯ç·šï¼‰
url = "https://pda.5284.gov.taipei/MQS/route.jsp?rid=10417"

# è¨­å®š Headersï¼Œé¿å…è¢«ç¶²ç«™æ“‹æ‰
headers = {
    "User-Agent": "Mozilla/5.0"
}

# ç™¼é€ GET è«‹æ±‚
response = requests.get(url, headers=headers)

# ç¢ºä¿è«‹æ±‚æˆåŠŸ
if response.status_code == 200:
    soup = BeautifulSoup(response.text, "html.parser")
    
    # æ‰¾å‡ºæ‰€æœ‰è¡¨æ ¼
    tables = soup.find_all("table")

    rows = []

    for table in tables:
        for tr in table.find_all("tr"):  # ç¢ºä¿æŠ“åˆ°æ‰€æœ‰ç«™é»
            td_list = tr.find_all("td")
            if len(td_list) >= 2:
                stop_name = html.unescape(td_list[0].text.strip())  # ç«™å
                arrival_time = html.unescape(td_list[1].text.strip())  # é è¨ˆåˆ°ç«™æ™‚é–“

                # ä¿®æ­£ a_tag è®Šæ•¸çš„éŒ¯èª¤
                a_tag = td_list[0].find("a")  # æª¢æŸ¥ç«™åå…§æ˜¯å¦æœ‰ <a> é€£çµ
                stop_link = a_tag["href"] if a_tag and "href" in a_tag.attrs else None

                rows.append({"ç«™é»åç¨±": stop_name, "é è¨ˆåˆ°ç«™æ™‚é–“": arrival_time, "é€£çµ": stop_link})

    # å­˜æˆ CSV æª”æ¡ˆ
    df = pd.DataFrame(rows)
    df.to_csv("bus_stations_times.csv", index=False, encoding="utf-8-sig")
    print("âœ… å·²æˆåŠŸå­˜æˆ bus_stations_times.csv")

else:
    print("âŒ ç„¡æ³•å–å¾—ç¶²é å…§å®¹ï¼Œè«‹æª¢æŸ¥ç¶²å€")
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time

# è¨­å®š User-Agent é¿å…è¢«å°é–
headers = {
    "User-Agent": "Mozilla/5.0"
}

# ç›®æ¨™ç¶²ç«™ï¼ˆè«‹æ”¹æˆä½ çš„å…¬è»Šç¶²ç«™é¦–é ï¼‰
BASE_URL = "https://bus-website.com/"
MAIN_URL = BASE_URL + "bus_stops_list"  # å…¬è»Šç«™åˆ—è¡¨é é¢ï¼ˆè«‹æ›¿æ›ç‚ºæ­£ç¢ºç¶²å€ï¼‰

# å…ˆæŠ“å–æ‰€æœ‰å…¬è»Šç«™é»çš„é€£çµ
response = requests.get(MAIN_URL, headers=headers)
if response.status_code != 200:
    print("âŒ ç„¡æ³•ç²å–å…¬è»Šç«™åˆ—è¡¨ï¼Œè«‹æª¢æŸ¥ç¶²å€")
    exit
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time

# è¨­å®š Headers é¿å…è¢«æ“‹
headers = {
    "User-Agent": "Mozilla/5.0"
}

# ç›®æ¨™ç¶²å€ï¼ˆæ›¿æ›æˆä½ çš„å…¬è»Šè·¯ç·šç¶²å€ï¼‰
URL = "https://pda5284.gov.taipei/MQS/route.jsp?rid=10417"

# ç™¼é€è«‹æ±‚
response = requests.get(URL, headers=headers)
if response.status_code != 200:
    print("âŒ ç„¡æ³•ç²å–å…¬è»Šæ™‚åˆ»è¡¨ï¼Œè«‹æª¢æŸ¥ç¶²å€")
    exit()

# è§£æ HTML
soup = BeautifulSoup(response.text, "html.parser")

# æ‰¾åˆ°ç«™é»æ™‚åˆ»è¡¨
tables = soup.find_all("table")

if not tables:
    print("âŒ æ²’æœ‰æ‰¾åˆ°ä»»ä½•å…¬è»Šæ™‚åˆ»è¡¨ï¼Œè«‹æª¢æŸ¥ HTML çµæ§‹")
    exit()

print(f"âœ… æ‰¾åˆ° {len(tables)} å€‹å…¬è»Šæ™‚åˆ»è¡¨")

# å­˜æ”¾æ‰€æœ‰ç«™é»è³‡è¨Š
all_data = []

# è§£ææ¯å€‹ç«™é»çš„è³‡è¨Š
for table in tables:
    for tr in table.find_all("tr"):
        td_list = tr.find_all("td")
        if len(td_list) >= 2:  # ç¢ºä¿æœ‰ç«™é»èˆ‡æ™‚é–“
            stop_name = td_list[0].text.strip()  # ç«™å
            arrival_time = td_list[1].text.strip()  # é è¨ˆåˆ°ç«™æ™‚é–“
            all_data.append({
                "ç«™é»åç¨±": stop_name,
                "é è¨ˆåˆ°ç«™æ™‚é–“": arrival_time
            })

# å­˜æˆ CSV æª”æ¡ˆ
df = pd.DataFrame(all_data)
df.to_csv("taipei_bus_times.csv", index=False, encoding="utf-8-sig")

print("ğŸ‰ å…¬è»Šæ™‚åˆ»è¡¨å·²å­˜æˆ taipei_bus_times.csv")


